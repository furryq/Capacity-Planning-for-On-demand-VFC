{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34888a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import time\n",
    "import pickle\n",
    "import random\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as et \n",
    "import warnings\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "plt.rcParams['figure.figsize'] = (20.0, 10.0)\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa91b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_docs(author):\n",
    "    author_attr = author.attrib\n",
    "    for doc in author.iter('vehicle'):\n",
    "        doc_dict = author_attr.copy()\n",
    "        doc_dict.update(doc.attrib)\n",
    "        #doc_dict['data'] = doc.text\n",
    "        yield doc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81acf0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_author(etree):\n",
    "    for author in etree.iter('timestep'):\n",
    "        for row in iter_docs(author):\n",
    "            yield row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc789dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files = glob.glob(\"*.xml\")[4:15]\n",
    "input_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a9040f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range(start=\"2022-02-28\",end=\"2022-03-10\")\n",
    "\n",
    "clusters = pd.read_pickle('clusters_14.pkl')\n",
    "dic = {str(clusters[i][j]):i for i in range(len(clusters)) for j in range(len(clusters[i]))}\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for i in range(10):\n",
    "    data = et.parse(input_files[i])\n",
    "    df1 = pd.DataFrame(list(iter_author(data)))\n",
    "    df1['time'] = df1['time'].astype('float')\n",
    "    df1['time'] = df1['time'].astype('int')\n",
    "    df1['seg0'] = df1['lane'].str.split('to').str[0]\n",
    "    df1['seg1'] = df1['lane'].str.split(':n').str[1].str.split('_').str[0]\n",
    "    df1['seg'] = df1['seg1'].fillna(df1['seg0'])\n",
    "    df1['cl'] = df1['seg'].map(dic)\n",
    "    df1['cl'] = df1['cl'].astype('int')\n",
    "    df2 = pd.DataFrame()\n",
    "    for time in df1['time'].unique():\n",
    "        df2[time] = df1[df1['time']==time]['cl'].value_counts().reindex(list(range(0,len(clusters))),fill_value=0)\n",
    "    df2 = df2.T\n",
    "    df2.index = [str(dates[i])+\" \"+str(datetime.timedelta(seconds = index)) for index in df2.index]\n",
    "    df2.index = pd.to_datetime(df2.index)\n",
    "    if i== 0:\n",
    "        df = df2\n",
    "    else:\n",
    "        df = pd.concat([df, df2])\n",
    "\n",
    "df_re = df.resample('H').max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfa0ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.rcParams[\"figure.figsize\"] = (20,3)\n",
    "df_re.plot(legend=None)\n",
    "plt.grid()\n",
    "plt.ylabel('Traffic flow')\n",
    "plt.xlabel('Time')\n",
    "# xlim = np.arange(0, 60* 60 *24, 60*60*4)\n",
    "# plt.xticks(xlim, [str(n).zfill(2) + ':00' for n in np.arange(0, 24, 4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46d55f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the d and q parameters to take any value between 0 and 1\n",
    "q = d = range(0, 2)\n",
    "# Define the p parameters to take any value between 0 and 3\n",
    "p = range(3, 4)\n",
    "\n",
    "# Generate all different combinations of p, q and q triplets\n",
    "pdq = list(itertools.product(p, d, q))\n",
    "\n",
    "# Generate all different combinations of seasonal p, q and q triplets\n",
    "seasonal_pdq = [(x[0], x[1], x[2], 24) for x in list(itertools.product(p, d, q))]\n",
    "\n",
    "# print('Examples of parameter combinations for Seasonal ARIMA...')\n",
    "# print('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[1]))\n",
    "# print('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[2]))\n",
    "# print('SARIMAX: {} x {}'.format(pdq[2], seasonal_pdq[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4710b22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = df_re['2022-02-28':'2022-03-08']\n",
    "test_set = df_re['2022-03-09':'2022-03-09']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8ff107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SARIMA(train_data, test_data):\n",
    "    # Train the model\n",
    "    warnings.filterwarnings(\"ignore\") # specify to ignore warning messages\n",
    "    AIC = []\n",
    "    SARIMAX_model = []\n",
    "    for param in pdq:\n",
    "        for param_seasonal in seasonal_pdq:\n",
    "            try:\n",
    "                mod = sm.tsa.statespace.SARIMAX(train_data,\n",
    "                                                order=param,\n",
    "                                                seasonal_order=param_seasonal,\n",
    "                                                enforce_stationarity=False,\n",
    "                                                enforce_invertibility=False)\n",
    "\n",
    "                results = mod.fit()\n",
    "\n",
    "                print('SARIMAX{}x{} - AIC:{}'.format(param, param_seasonal, results.aic), end='\\r')\n",
    "                AIC.append(results.aic)\n",
    "                SARIMAX_model.append([param, param_seasonal])\n",
    "            except:\n",
    "                continue\n",
    "    parameter = [min(AIC), SARIMAX_model[AIC.index(min(AIC))][0],SARIMAX_model[AIC.index(min(AIC))][1]]\n",
    "    print('The smallest AIC is {} for model SARIMAX{}x{}'.format(min(AIC), SARIMAX_model[AIC.index(min(AIC))][0],SARIMAX_model[AIC.index(min(AIC))][1]))\n",
    "\n",
    "    # Fit the model\n",
    "    mod = sm.tsa.statespace.SARIMAX(train_data,\n",
    "                                    order=SARIMAX_model[AIC.index(min(AIC))][0],\n",
    "                                    seasonal_order=SARIMAX_model[AIC.index(min(AIC))][1],\n",
    "                                    enforce_stationarity=False,\n",
    "                                    enforce_invertibility=False)\n",
    "    results = mod.fit()\n",
    "\n",
    "    # Prediction\n",
    "    pred2 = results.get_forecast('2022-03-09 23:00:00')\n",
    "    pred2_ci = pred2.conf_int()\n",
    "    prediction = pred2.predicted_mean['2022-03-09 00:00:00':'2022-03-09 23:00:00'].values\n",
    "\n",
    "    # Mean Absolute Percentage Error\n",
    "    truth = test_data.values\n",
    "    # MAPE = np.mean(np.abs((truth - prediction) / truth)) * 100\n",
    "    MAE = np.mean(np.abs(truth - prediction))\n",
    "    print('The Mean Absolute Percentage Error for the forecast of 2022-03-09 is {:.2f}'.format(MAE))\n",
    "    return parameter, prediction, MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60828e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "MAEs = []\n",
    "parameters = []\n",
    "for cl in range(len(clusters)):\n",
    "    train_data = train_set[cl]\n",
    "    test_data = test_set[cl]\n",
    "    parameter, prediction, MAE = SARIMA(train_data, test_data)\n",
    "    parameters.append(parameter)\n",
    "    predictions.append(prediction)\n",
    "    MAEs.append(MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82833b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(MAEs)/len(MAEs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877e712d",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_cl = pd.DataFrame(predictions).T.round(0).astype('int')\n",
    "flow_cl.to_pickle('flow_%i.pkl'%len(clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660ed2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(df_re['2022-03-09':'2022-03-09'].T.sum())\n",
    "df3[1] = pd.DataFrame(predictions).round(0).astype('int').sum().tolist()\n",
    "plt.plot(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645a64f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['error'] = abs(df3[0]-df3[1])\n",
    "df3['error'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6e60b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['error'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ac59e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['error'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d694ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
